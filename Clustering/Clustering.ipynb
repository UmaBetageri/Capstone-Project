#pip install geopandas
# install Cartopy using : https://stackoverflow.com/questions/70177062/cartopy-not-able-to-identify-geos-for-proj-install-on-windows

import pyproj
import numpy as np
import seaborn as sns
import pandas as pd
import matplotlib.pyplot as plt
from shapely.geometry import Point
import plotly.express as ex
from plotly.subplots import make_subplots
import plotly.graph_objs as go
from sklearn.cluster import KMeans
import geopandas as gpd
from sklearn.metrics import silhouette_score
from sklearn.metrics import calinski_harabasz_score
from sklearn.metrics import davies_bouldin_score

#Contains the world map boundaries
df_world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))

US_data = pd.read_csv("US_Data.csv")
CA_data = pd.read_csv("CA_Data.csv")

US_data.head()

US_data.columns

data = US_data.loc[US_data.Magnitude>5, ['Latitude', 'Longitude','Magnitude']]
data['Coordinates'] = list(zip(data.Longitude, data.Latitude))
data['Coordinates'] = data['Coordinates'].apply(Point)
data.head()

print("Minimum magnitude: ",data["Magnitude"].min())
print("Maximum magnitude: ",data["Magnitude"].max())

#Convert the pandas dataframe to geopandas dataframe
gdf = gpd.GeoDataFrame(data, geometry='Coordinates')

ax = df_world["geometry"].boundary.plot(figsize=(20,16))
# We can now plot our GeoDataFrame.
gdf.plot(ax=ax, color='red')

plt.show()

def get_day_of_week(sir):
    return sir.weekday()
def get_month(sir):
    return sir.month
def get_year(sir):
    return sir.year

US_data.Date = pd.to_datetime(US_data.Date)
US_data['Year'] = US_data.Date.apply(get_year)
US_data['Month'] = US_data.Date.apply(get_month)
US_data['Year'] = US_data.Date.apply(get_year)

CA_data.Date = pd.to_datetime(CA_data.Date)
CA_data['Year'] = CA_data.Date.apply(get_year)
CA_data['Month'] = CA_data.Date.apply(get_month)
CA_data['Year'] = CA_data.Date.apply(get_year)

US_data.head()

tmp = US_data.groupby(by='Year').count()
tmp = tmp.reset_index()[['Year','Date']]
fig = ex.line(tmp,x='Year',y='Date')
fig.update_layout(
    title= 'Number Of Earthquakes Over The Years 2000-2023',
    xaxis = dict(
        tickmode = 'linear',
        tick0 = 0.0,
        dtick = 1
    )
)
fig.add_shape(type="line",
    x0=tmp['Year'].values[0], y0=tmp['Date'].mean(), x1=tmp['Year'].values[-1], y1=tmp['Date'].mean(),
    line=dict(
        color="Red",
        width=2,
        dash="dashdot",
    ),
        name='Mean'
)
fig.show()

tmp = CA_data.groupby(by='Year').count()
tmp = tmp.reset_index()[['Year','Date']]
fig = ex.line(tmp,x='Year',y='Date')
fig.update_layout(
    title= 'Number Of Earthquakes Over The Years 2000-2023',
    xaxis = dict(
        tickmode = 'linear',
        tick0 = 0.0,
        dtick = 1
    )
)
fig.add_shape(type="line",
    x0=tmp['Year'].values[0], y0=tmp['Date'].mean(), x1=tmp['Year'].values[-1], y1=tmp['Date'].mean(),
    line=dict(
        color="Red",
        width=2,
        dash="dashdot",
    ),
        name='Mean'
)
fig.show()

fig = make_subplots(
    rows=2, cols=2,
    column_widths=[0.6, 0.4],subplot_titles=('Location Of Recorded Earthquakes','Distriubtion Of Magnitudes',  'Distriubtion Of Depths'),
    row_heights=[0.4, 0.6],
    specs=[[{"type": "scattergeo", "rowspan": 2}, {"type": "histogram"}],
           [            None                    , {"type": "bar"}]])

fig.add_trace(
    go.Scattergeo(lat=US_data["Latitude"],
                  lon=US_data["Longitude"],
                  mode="markers",
                  hoverinfo="text",
                  text=US_data.Magnitude,
                  showlegend=False,
                  marker=dict(color="crimson", size=6, opacity=0.8)),
    row=1, col=1
)

fig.add_trace(
    go.Histogram(x=US_data.Magnitude,name='Magnitude'),
    row=1, col=2
)
fig.add_trace(
    go.Histogram(x=US_data.Depth,name='Depth'),
    row=2, col=2
)


fig.update_geos(
    projection_type="orthographic",
    landcolor="white",
    oceancolor="MidnightBlue",
    showocean=True,
    lakecolor="LightBlue"
)

fig.update_xaxes(tickangle=45)

fig.update_layout(
    template="plotly_dark",
    margin=dict(r=10, t=25, b=40, l=60),
    
)

fig.show()

plt.figure(figsize=(20,11))
ax = sns.distplot(US_data['Latitude'],label='Latitude')
ax.set_title('Distribution Of Earthquake Latitudes',fontsize=19)
ax.set_ylabel('Density',fontsize=16)
ax.set_xlabel('Latitude',fontsize=16)

plt.show()

plt.figure(figsize=(20,11))
ax = sns.distplot(US_data['Longitude'],label='Longitude',color='teal')
ax.set_title('Distribution Of Earthquake Longitudes',fontsize=19)
ax.set_ylabel('Density',fontsize=16)
ax.set_xlabel('Longitude',fontsize=16)

plt.show()

plt.figure(figsize=(20,11))
ax = sns.distplot(US_data['Magnitude'],label='Magnitude',color='teal')
ax.set_title('Distribution Of Earthquake Magnitudes',fontsize=19)
ax.set_ylabel('Density',fontsize=16)
ax.set_xlabel('Magnitude',fontsize=16)

plt.show()

#Clustring
from sklearn.cluster import KMeans,DBSCAN
DB = DBSCAN(eps=0.5,algorithm='ball_tree',min_samples=15)
c_data = US_data.copy()
DB.fit(US_data[['Latitude', 'Longitude','Magnitude']])
labels = DB.labels_

# Number of clusters in labels, ignoring noise if present.
n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)
n_noise_ = list(labels).count(-1)

print("Estimated number of clusters: %d" % n_clusters_)
print("Estimated number of noise points: %d" % n_noise_)

c_data['clusters'] = labels
c_data = c_data.loc[c_data['clusters']!=-1, :]
c_data.head()

fig = ex.scatter(c_data, x="Latitude", y="Longitude", hover_name="Magnitude", color = "clusters", size_max=60)
fig.update_layout(
     height=800)
fig.show()

fig = ex.scatter_3d(c_data,x='Longitude',y='Latitude',z='Magnitude',color='clusters',height=900, size_max=18,
               opacity=0.7)
fig.show()

#Clustring
from sklearn.cluster import KMeans,DBSCAN
DB = DBSCAN(eps=0.5,algorithm='ball_tree',min_samples=15)
c_data = CA_data.copy()
DB.fit(CA_data[['Magnitude']])
labels = DB.labels_

# Number of clusters in labels, ignoring noise if present.
n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)
n_noise_ = list(labels).count(-1)

print("Estimated number of clusters: %d" % n_clusters_)
print("Estimated number of noise points: %d" % n_noise_)


fig = ex.scatter_3d(c_data,x='Magnitude',color=labels,height=900, size_max=18,symbol=labels, opacity=0.7)
fig.show()

X = US_data[['Latitude', 'Longitude','Magnitude']].values
Y = US_data[['Latitude', 'Longitude','Depth']].values

### Silhouette for Lat, Long, Magnitude

clusters = [4, 5, 6, 7, 8]

silhouette_avg = []

for num_clusters in clusters:
    print(f'fitting for {num_clusters}')
    # initialise kmeans
    kmeans = KMeans(n_clusters=num_clusters)
    kmeans.fit(X)
    cluster_labels = kmeans.labels_
 
 # silhouette score
    silhouette_avg.append(silhouette_score(X, cluster_labels))
    print('fitted')
    



plt.plot(clusters,silhouette_avg,'bx-')    
plt.xlabel('Values of K') 
plt.ylabel('Silhouette score') 
plt.title('Silhouette analysis For Optimal k')
plt.show()


# Create a KMeans instance with 5 clusters: model
model = KMeans(n_clusters=4, random_state=2)

# Fit model to points
model.fit(X)
labels = model.labels_
centroids = model.cluster_centers_

X_df = pd.DataFrame(X)
X_df['Cluster'] = model.labels_

bins = [1, 4, 6, 8]
X_df['Magnitude_range'] = pd.cut(X_df[2], bins)
X_df['Magnitude_range'].unique()
#X_df.groupby('Cluster','Magnitude_range').count()

DB = davies_bouldin_score(X, labels)
print()

s = silhouette_score(X, labels, metric="euclidean")

c = calinski_harabasz_score(X, labels)

print(f'Silhouette Score : {s}')
print(f'Calinski_harabasz_score : {c}')
print(f'Davies_bouldin_score: {DB}')

# Plot the earthquakes
fig, ax = plt.subplots(figsize=(10, 10))
ax.scatter(X[:,0], X[:,1], c=labels)
ax.scatter(centroids[:, 0], centroids[:, 1], marker='x', s=200, linewidths=3, color='r')
ax.set_xlabel('Longitude')
ax.set_ylabel('Latitude')
ax.set_title('Earthquake Clustering')
plt.show()

### Silhouette for Lat, Long, Depth

clusters = [3,4, 5, 6, 7, 8]

silhouette_avg = []

for num_clusters in clusters:
    print(f'fitting for {num_clusters}')
    # initialise kmeans
    kmeans = KMeans(n_clusters=num_clusters)
    kmeans.fit(Y)
    cluster_labels = kmeans.labels_
 
 # silhouette score
    silhouette_avg.append(silhouette_score(Y, cluster_labels))
    print('fitted')
    

plt.plot(clusters,silhouette_avg,'bx-')    
plt.xlabel('Values of K') 
plt.ylabel('Silhouette score') 
plt.title('Silhouette analysis For Optimal k')
plt.show()

# Create a KMeans instance with 3 clusters: model
model = KMeans(n_clusters=4, random_state=2)

# Fit model to points
model.fit(Y)
labels = model.labels_
centroids = model.cluster_centers_
Y_df = pd.DataFrame(Y)
Y_df['Cluster'] = model.labels_

# Plot the earthquakes
fig, ax = plt.subplots(figsize=(10, 10))
ax.scatter(Y[:,0], Y[:,1], c=labels)
ax.scatter(centroids[:, 0], centroids[:, 1], marker='x', s=200, linewidths=3, color='r')
ax.set_xlabel('Longitude')
ax.set_ylabel('Latitude')
ax.set_title('Earthquake Clustering')
plt.show()

DB = davies_bouldin_score(Y, labels)

s = silhouette_score(Y, labels, metric="euclidean")

c = calinski_harabasz_score(Y, labels)

print(f'Silhouette Score : {s}')
print(f'Calinski_harabasz_score : {c}')
print(f'Davies_bouldin_score: {DB}')

z = Y_df['Cluster'].unique()
z.sort()
for x in z:
    print(f"Cluster : {x}")
    print(f"Minimum Depth : {Y_df[Y_df.Cluster==x][2].min()}")
    print(f"Maximum Depth : {Y_df[Y_df.Cluster==x][2].max()}")

z = X_df['Cluster'].unique()
z.sort()
for x in z:
    print(f"Cluster : {x}")
    print(f"Minimum Magnitude : {X_df[X_df.Cluster==x][2].min()}")
    print(f"Maximum Magnitude : {X_df[X_df.Cluster==x][2].max()}")





X = CA_data.loc[CA_data.Magnitude>5, ['Latitude', 'Longitude','Magnitude']].values
Y = CA_data.loc[CA_data.Magnitude>5, ['Latitude', 'Longitude','Depth']].values


# Create a KMeans instance with 5 clusters: model
model = KMeans(n_clusters=5, random_state=2)

# Fit model to points
model.fit(X)
labels = model.labels_
centroids = model.cluster_centers_

X_df = pd.DataFrame(X)
X_df['Cluster'] = model.labels_

# Plot the earthquakes
fig, ax = plt.subplots(figsize=(10, 10))
ax.scatter(X[:,0], X[:,1], c=labels)
ax.scatter(centroids[:, 0], centroids[:, 1], marker='x', s=200, linewidths=3, color='r')
ax.set_xlabel('Longitude')
ax.set_ylabel('Latitude')
ax.set_title('Earthquake Clustering')
plt.show()

# Create a KMeans instance with 3 clusters: model
model = KMeans(n_clusters=5, random_state=2)

# Fit model to points
model.fit(Y)
labels = model.labels_
centroids = model.cluster_centers_
Y_df = pd.DataFrame(Y)
Y_df['Cluster'] = model.labels_

# Plot the earthquakes
fig, ax = plt.subplots(figsize=(10, 10))
ax.scatter(Y[:,0], Y[:,1], c=labels)
ax.scatter(centroids[:, 0], centroids[:, 1], marker='x', s=200, linewidths=3, color='r')
ax.set_xlabel('Longitude')
ax.set_ylabel('Latitude')
ax.set_title('Earthquake Clustering')
plt.show()



